{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import re\n",
    "import logging\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "train_path = '../Train_Data/'\n",
    "train_data_list = '../project-data/train.data.txt'\n",
    "\n",
    "dev_path = '../Dev_Data/'\n",
    "dev_data_list = '../project-data/dev.data.txt'\n",
    "\n",
    "test_path = '../Test_Data/'\n",
    "test_data_list = '../project-data/test.data.txt'\n",
    "\n",
    "def extract_tweet(tweet_id, dir_path):\n",
    "  try:\n",
    "    with open(f'{dir_path}{tweet_id}.json') as json_file:\n",
    "      data = json.load(json_file)\n",
    "      return {'tweet_id': data['id'],\n",
    "          'user_id' : data['user']['id'],\n",
    "              'followers_count' : data['user']['followers_count'],\n",
    "              'friends_count' : data['user']['friends_count'],\n",
    "              'listed_count' : data['user']['listed_count'],\n",
    "              'favourites_count' : data['user']['favourites_count'],\n",
    "              'verified' : data['user']['verified'],\n",
    "              'hastags' : data['entities']['hashtags'],\n",
    "              'text' : data['text'],            \n",
    "              'created_at' : data['created_at'],\n",
    "              'in_reply_to_status_id' : data['in_reply_to_status_id'],\n",
    "              'retweet_count': data['retweet_count'] ,   \n",
    "              'favorite_count': data['favorite_count']}\n",
    "  except FileNotFoundError:\n",
    "    logging.error(f\"Target {tweet_id} not found\")\n",
    "            \n",
    "    \n",
    "def extract_reply(tweet_id, dir_path):\n",
    "  try:\n",
    "    with open(f'{dir_path}{tweet_id}.json') as json_file:\n",
    "      data = json.load(json_file)\n",
    "      return {'text' : data['text'],            \n",
    "              'created_at' : data['created_at']}\n",
    "  except FileNotFoundError:\n",
    "    logging.info(f\"reply {tweet_id} not found\")\n",
    "\n",
    "  \n",
    "\n",
    "def process_tweet_text(text):\n",
    "  text = text.lower()\n",
    "  text = re.sub(r'https?:\\/\\/\\S+', '', text)\n",
    "  text = re.sub(r\"www\\.[a-z]?\\.?(com)+|[a-z]+\\.(com)\", '', text)\n",
    "  text = re.sub(r'@\\w+', '', text)\n",
    "  return text\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "process list of replies into single dict\n",
    "\"\"\"\n",
    "def process_replies(replies):\n",
    "  if len(replies) ==0:\n",
    "    return {'reply_avg_sent' : 0,\n",
    "          'reply_sent_trend': 0, \n",
    "          'reply_text': ''\n",
    "          }\n",
    "  reply_df = pd.DataFrame(replies)\n",
    "  reply_df.sort_values('created_at', inplace=True)\n",
    "  reply_df['clean_text'] = reply_df.text.apply(process_tweet_text)\n",
    "  reply_df['sent'] =  reply_df.text.apply(lambda x: sid.polarity_scores(x)['compound'])\n",
    "  return {'reply_avg_sent' : reply_df.sent.mean(),\n",
    "          'reply_sent_trend': 0, #is the reply sentiment up or down\n",
    "          'reply_text': ' '.join(list(reply_df.clean_text))\n",
    "          }\n",
    "\n",
    "\n",
    "\n",
    "def process_data_file(list_file_path, tweet_path):\n",
    "  logging.basicConfig(filename=f'{tweet_path}process.log', level=logging.INFO)\n",
    "  with open(list_file_path, \"r\") as f:\n",
    "    lines = list(f)\n",
    "    target_tweets = []\n",
    "    for line in lines:\n",
    "      tweets = line.split(',')\n",
    "      for idx, tweet in enumerate(tweets):\n",
    "        reply_texts = ''\n",
    "        reply_followers = 0\n",
    "        reply_tweets = []\n",
    "        if idx == 0: # target tweet\n",
    "          tweet_dict = extract_tweet(tweet.strip(), tweet_path)\n",
    "          if tweet_dict is None:\n",
    "            logging.error('warning -- Missing a target tweet')\n",
    "            break\n",
    "        else:\n",
    "          reply = extract_reply(tweet.strip(), tweet_path)\n",
    "          if reply is not None:\n",
    "            reply_tweets.append(reply)\n",
    "      if tweet_dict is not None:\n",
    "        target_tweets.append({**tweet_dict, **process_replies(reply_tweets)})\n",
    "    return pd.DataFrame(target_tweets)\n",
    "\n",
    "a = process_data_file(dev_data_list, dev_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['clean_text'] = a.text.apply(process_tweet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[['clean_text','text']].to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "\n",
    "json_files = [pos_json for pos_json in os.listdir(test_path) if pos_json.endswith('.json')]\n",
    "truncates =[]\n",
    "for i in json_files:\n",
    "    with open(f'{test_path}{i}') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        truncates.append(data['truncated'])  \n",
    "       # if data['truncated']:\n",
    "           # print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
